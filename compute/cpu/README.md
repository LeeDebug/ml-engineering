### CPU

截至撰写本文时，机器学习工作负载对CPU的使用量不大，因此本章内容并不多。随着CPU逐渐向GPU靠拢，这种情况可能会改变，因此我预计本章将随着CPU的发展而发展。

#### 你需要多少个CPU核心

对于每块加速器，需要：

1. 每一个与加速器绑定的进程占用1个CPU核心；
2. 为每个`DataLoader`工作线程占用1个CPU核心——通常需要2到4个工作线程。

2个工作线程通常足够自然语言处理（NLP）模型使用，尤其是当数据已经预处理过的情况下。如果需要进行动态变换，这在计算机视觉模型或VLM中经常发生，可能需要3至4个工作线程，有时甚至更多。

目标是能够立即从`DataLoader`中拉取数据，并确保不会阻塞加速器的计算能力。这意味着你需要提前为下一迭代处理一批样本，在当前迭代运行的同时。换句话说，你的下一个批次不应比同一大小的批处理所需的单次迭代时间更长。

除了预处理之外，如果你从云端动态拉取数据而不是本地存储的话，还需要确保数据能够快速预获取以供供给工作线程并输入加速器炉膛。

将上述数量乘以加速器的数量，再添加几个操作系统核心（比如4个）。

如果节点有8块加速器且你有`n_workers`个，那么你需要 `8*(num_workers+1)+4` 个CPU核心。如果是NLP工作的话，通常每个加速器需要2个工作线程，因此 `8*(2+1)+4` => 28个CPU核心。如果进行计算机视觉训练，并且每个加速器需要4个工作线程，则为 `8*(4+1)+4` => 44个CPU核心。

如果你有许多非常活跃的进程数量超过了总的CPU核心数，一些进程将会被预取（即排队等待CPU核心可用）并绝对避免任何上下文切换。

但是现代云服务通常提供50到100多个CPU核心，因此通常有足够的核心可以分配。请参见[异步DataLoader](../../training/performance#asynchronous-dataloader)相关内容。

#### CPU卸载

一些框架，如 [Deepspeed](https://www.deepspeed.ai/tutorials/zero-offload/) 可以将某些计算工作卸载到CPU上而不会形成瓶颈。在这种情况下，你需要额外的CPU核心。

#### NUMA亲和性

请参见[NUMA亲和性](../../training/performance#numa-affinity)相关内容。

#### 超线程

[超线程技术](https://en.wikipedia.org/wiki/Hyper-threading)将每个物理核心虚拟化为两个，允许两个线程同时使用同一个CPU核心。根据负载类型的不同，这项特性可能会或可能不会提高整体性能。英特尔——这项技术的发明者——在某些情况下建议最多可获得30%的性能提升。

请参见[是否启用超线程](../../orchestration/slurm/performance.md#to-enable-hyper-threads-or-not)相关内容。